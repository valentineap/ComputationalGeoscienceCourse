{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8 - Reading and writing files\n",
    "\n",
    "So far, we have typed all the data for our programs in 'by hand'. However, as you have no doubt noticed, this quickly gets tedious. It is useful to be able to read and write data files, allowing information to be stored and shared with other people.\n",
    "\n",
    "In order to read a data file, we need to understand what information it contains, and how this has been encoded. This is generally referred to as the 'file format'. Different programs produce files in different formats - a photograph in `.jpeg` format cannot be read by a spreadsheet package, which might expect to receive files in `.xlsx` format.\n",
    "\n",
    "The simplest file format for storing and transferring scientific data is a plain text file in 'ascii' ('American Standard Code for Information Exchange') format. This is the sort of file that can be read and produced using a simple text editor such as 'notepad' (on Windows) or 'TextEdit' (on a Mac). Commonly, such files will have an extension such as `.txt` or `.dat`.\n",
    "\n",
    "Reading ascii files in Python is a four-step process:\n",
    "1. Open the file;\n",
    "2. Read each line from the file;\n",
    "3. Parse each line (i.e., extract the required information from it);\n",
    "4. Close the file.\n",
    "\n",
    "We assume that the file is already saved on your computer, and you know the 'path' to the file. To open the file, we use the `open()` function, which returns a `file` object. It is important to assign this to a variable (here, `fp`) so that we can continue to access the open file.\n",
    "```python\n",
    "filename = 'sample.dat'\n",
    "fp = open(filename,'r')\n",
    "```\n",
    "Here, `filename` is a variable holding the file name (or file path and name, if it is not in our current working directory), and the second argument, `'r'`, specifies that we want to open the file for reading only.\n",
    "\n",
    "Once the file is open, we can read from it. There are various ways of doing this, but for small files the simplest method is generally to call the `readlines()` function, which returns the entire file in the form of a list:\n",
    "```python\n",
    "lines = fp.readlines()\n",
    "```\n",
    "Each element of the list `lines` is now a string, containing one of the lines from the file `sample.dat`. Since we have read all the information in the file, we can now close the file:\n",
    "```python\n",
    "fp.close()\n",
    "```\n",
    "**&#10148; Try it out!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening and closing files explicitly is useful to illustrate how Python handles reading and writing files. However, doing this in practice can get quite messy because these 'connections' to files stay open until you explicitly close them. With single files, thie can lead to data corruption and data loss, with more complex scripts you might open 10,000 files and not close any of them, clogging up your computer!\n",
    "\n",
    "Luckily, Python has a really handy construct for dealing with this automatically, called '[context managers](https://jeffknupp.com/blog/2016/03/07/python-with-context-managers/)'. They have a number of uses, but in the case of reading/writing files, you create a 'context' that contains a connection to a file, which is automatically closed when the code within the context is finished. This sounds complex... so an example:\n",
    "\n",
    "```python\n",
    "filename = 'sample.dat'\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "```\n",
    "\n",
    "The `with` statement tells python that the file you're giving it is only used in the following indented code, and can be closed afterwards.\n",
    "\n",
    "This performs exactly the same as manually opening and closing the file, as above, but automatically cleans up after you.\n",
    "\n",
    "**&#10148; Try it out!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a list of strings, you can use the list- and string-parsing tools we have already encountered to extract the necessary data and store it in appropriate data structures.\n",
    "\n",
    "The file `sample.dat` contains records of the mass and volume of twenty samples of a given material.\n",
    "\n",
    "**&#10148; Read the data from this file, compute the density of each sample and hence the average density of the material.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write data to file, we need to first open the file for writing. This can be done by using `'w'` instead of `'r'` when opening the file. Note that if a file already exists with the specified name, it will be immediately overwritten and lost. To avoid this, you can instead use `'x'` when opening the file. This will throw an error if there is an existing file, rather than overwrite it. Again, when opening the file it is important to assign the result of `open()` to a variable, so we can write to it.\n",
    "\n",
    "```python\n",
    "outputfile = 'processed_samples.dat'\n",
    "fp = open(outputfile,'w')\n",
    "```\n",
    "\n",
    "Once the file is open, we can write any text strings to it by calling the `write()` function. Remember, to insert a new line, you use the symbol `'\\n'`, otherwise everything will be on a single line:\n",
    "```python\n",
    "fp.write(\"Hello!\\n\")\n",
    "fp.write(\"This is some text to store in a file... \")\n",
    "line = \"The file has only two lines.\"\n",
    "fp.write(line)\n",
    "```\n",
    "Once everything is written to the file, call `close()` to close it.\n",
    "```python\n",
    "fp.close()\n",
    "```\n",
    "**&#10148; Create a new file, based on the data you read earlier. It should contain three columns: mass, sample volume and sample density. All quantities should be in SI units.** \n",
    "\n",
    "Remember, you can use the string-formatting tools we encountered in the last exercise to control how your numbers are written out. You can open a text file by clicking its name in Jupyter's file browser. Verify that the file has been correctly written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the examples above, we just saw how to read and write data using Python built-in methods. Libraries such as Numpy or Pandas provide further capacities for reading and writing data.\n",
    "\n",
    "For instance, one can use the `numpy.genfromtxt()` and `numpy.savetxt()` functions to import the data and do the same calculation as above and save the result. \n",
    "\n",
    "**&#10148; Import Numpy, look at the help of those functions and try to reproduce the read/calculate/write procedure with Numpy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice an advantage of importing your data through Numpy? Compare the type of the data after import via Numpy or via load() to answer this question.\n",
    "\n",
    "If you are going to continue working with Numpy in a project, you could also save the Numpy arrays in Numpy format (.npy) and load them late with the functions `numpy.save()` and `numpy.load()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A benefit of using numpy format is to have fast read/write speed, which can be an advantage when dealing with large datasets (>100 Mb). However, always remember that for long term storage plain text formats, such as ASCII or CSV, should be preferred as this can be read by any program/language/human, whereas .npy files are specific to Numpy.\n",
    "\n",
    "### Other Formats\n",
    "\n",
    "In science, you'll come across all sorts of data in every imagineable format. It's impossible to cover them all here, but this exercise should give you an understanding of ways of reading and writing different types of data, so that you can tackle these myriad formats.\n",
    "\n",
    "Two very common types of files that you'll come across are Microsoft Excel spreadsheets, and image data, which we *will* cover here.\n",
    "\n",
    "#### Microsoft Excel\n",
    "Try opening a spreadsheet in a text editor... data in these files is stored in a proprietary binary format, which *can't* be read in plain text. Python has two mature packages to read and write these files: `xlrd` and `xlwt`. These packages work very well, but are a bit hard to get to grips with. In practice, the easiest way to read and write excel files is via a higher-level library like `pandas`, which handles all the under-the-hood mechanics for you.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "excel_file = 'my_file.xlsx'\n",
    "dat = pd.read_excel(excel_file, sheet_name='my_data')\n",
    "dat.to_excel('my_new_file.xlsx')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images\n",
    "Images come in a variety of formats. The most basic will be a 2D array of plain text numbers, which can be imported using numpy, and the more advanced can be multi-channel TIFF images, which are a bit more complex.\n",
    "\n",
    "Python has a good set of tools for reading, converting and writing these images, in a package called `pillow` - a development of hte '**P**ython **I**maging **L**ibrary'.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "from PIL import Image\n",
    "\n",
    "im = Image.open('my_image.jpg')\n",
    "im.convert('L')  # convert to black and white\n",
    "imarray = np.array(im)  # get image as 2D array \n",
    "```\n",
    "\n",
    "You can do a *lot* with `PIL`... see [the documentation](https://pillow.readthedocs.io/en/3.1.x/index.html) for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Libraries\n",
    "There are also a number of libraries out there with extensive data import/export capabilities. In particular:\n",
    "- [Pandas](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html), specialised in tabular data, and can interacte with SQL and Excel;\n",
    "- [HDF5](https://www.h5py.org/), a format targeted at large datasets, very handy, easy to interact with Numpy, and also adequate for long term storage.\n",
    "- [Pickle](https://docs.python.org/3/library/pickle.html), implements binary protocols for serializing and de-serializing a Python object structure. This allows one to store not only arrays, but also Python objects.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
